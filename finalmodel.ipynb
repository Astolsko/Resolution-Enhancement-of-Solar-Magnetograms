{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torchsummary import summary\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, random_split\n",
    "import random\n",
    "\n",
    "# from our codebase\n",
    "from conv_layer import conv_layer\n",
    "from RLFB import RLFB\n",
    "from SUBP import SubPixelConvBlock  \n",
    "from Trainning_Loop import train_model, CharbonnierLoss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MESR(nn.Module):\n",
    "    def __init__(self, in_channels, mid_channels, out_channels, num_blocks=12, esa_channels=16, upscale_factor=2):\n",
    "        super(MESR, self).__init__()\n",
    "\n",
    "        self.conv_in = conv_layer(in_channels, mid_channels, 3)\n",
    "        self.RLFB_blocks = nn.Sequential(*[RLFB(mid_channels, esa_channels=esa_channels) for _ in range(num_blocks)])\n",
    "        self.conv_out = conv_layer(mid_channels, out_channels, 3)\n",
    "        self.sub_pixel_conv = SubPixelConvBlock(out_channels, out_channels, upscale_factor=upscale_factor)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out_conv_in = self.conv_in(x)  \n",
    "        out_RLFB = self.RLFB_blocks(out_conv_in)  \n",
    "        out_skip = out_RLFB + out_conv_in  \n",
    "        out = self.conv_out(out_skip)  \n",
    "        out = self.sub_pixel_conv(out)  \n",
    "        return out\n",
    "\n",
    "\n",
    "def model_summary(model, device):\n",
    "    model.to(device)\n",
    "    summary(model, input_size=(3, 256, 256)) # Change order & num of channels to match grayscale channel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SuperResolutionDataset(Dataset):\n",
    "    def __init__(self, lr_dir, hr_dir, lr_transform=None, hr_transform=None):\n",
    "        self.lr_dir = lr_dir\n",
    "        self.hr_dir = hr_dir\n",
    "        self.lr_images = os.listdir(lr_dir)\n",
    "        self.lr_transform = lr_transform\n",
    "        self.hr_transform = hr_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.lr_images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        lr_image_path = os.path.join(self.lr_dir, self.lr_images[idx])\n",
    "        hr_image_path = os.path.join(self.hr_dir, self.lr_images[idx])\n",
    "\n",
    "        lr_image = Image.open(lr_image_path).convert(\"RGB\")\n",
    "        hr_image = Image.open(hr_image_path).convert(\"RGB\")\n",
    "\n",
    "        if self.lr_transform:\n",
    "            lr_image = self.lr_transform(lr_image)\n",
    "        if self.hr_transform:\n",
    "            hr_image = self.hr_transform(hr_image)\n",
    "\n",
    "        return {'image': lr_image, 'label': hr_image}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataloaders(train_dataset, val_dataset, batch_size=24): # setting the batch size to 2\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    return train_loader, val_loader\n",
    "\n",
    "\n",
    "def setup_training(model, device, train_loader, val_loader, epochs=2, patience=50):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
    "    loss_function = CharbonnierLoss(epsilon=1e-6)\n",
    "    lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.1)\n",
    "\n",
    "    train_model(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        optimizer=optimizer,\n",
    "        loss_function=loss_function,\n",
    "        device=device,\n",
    "        epochs=epochs,\n",
    "        patience=patience,\n",
    "        val_interval=10,\n",
    "        lr_scheduler=lr_scheduler,\n",
    "        output_dir=\"./model_output\"  # Specify the output directory\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available!\n",
      "Number of available GPUs: 1\n",
      "Current device: 0\n",
      "Device name: NVIDIA RTX A6000\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 256, 256]           1,792\n",
      "            Conv2d-2         [-1, 64, 256, 256]          36,928\n",
      "              SiLU-3         [-1, 64, 256, 256]               0\n",
      "            Conv2d-4         [-1, 64, 256, 256]          36,928\n",
      "              SiLU-5         [-1, 64, 256, 256]               0\n",
      "            Conv2d-6         [-1, 64, 256, 256]          36,928\n",
      "              SiLU-7         [-1, 64, 256, 256]               0\n",
      "            Conv2d-8         [-1, 64, 256, 256]           4,160\n",
      "            Conv2d-9         [-1, 16, 256, 256]           1,040\n",
      "           Conv2d-10         [-1, 16, 127, 127]           2,320\n",
      "           Conv2d-11           [-1, 16, 41, 41]           2,320\n",
      "           Conv2d-12         [-1, 16, 256, 256]             272\n",
      "           Conv2d-13         [-1, 64, 256, 256]           1,088\n",
      "          Sigmoid-14         [-1, 64, 256, 256]               0\n",
      "              ESA-15         [-1, 64, 256, 256]               0\n",
      "             RLFB-16         [-1, 64, 256, 256]               0\n",
      "           Conv2d-17         [-1, 64, 256, 256]          36,928\n",
      "             SiLU-18         [-1, 64, 256, 256]               0\n",
      "           Conv2d-19         [-1, 64, 256, 256]          36,928\n",
      "             SiLU-20         [-1, 64, 256, 256]               0\n",
      "           Conv2d-21         [-1, 64, 256, 256]          36,928\n",
      "             SiLU-22         [-1, 64, 256, 256]               0\n",
      "           Conv2d-23         [-1, 64, 256, 256]           4,160\n",
      "           Conv2d-24         [-1, 16, 256, 256]           1,040\n",
      "           Conv2d-25         [-1, 16, 127, 127]           2,320\n",
      "           Conv2d-26           [-1, 16, 41, 41]           2,320\n",
      "           Conv2d-27         [-1, 16, 256, 256]             272\n",
      "           Conv2d-28         [-1, 64, 256, 256]           1,088\n",
      "          Sigmoid-29         [-1, 64, 256, 256]               0\n",
      "              ESA-30         [-1, 64, 256, 256]               0\n",
      "             RLFB-31         [-1, 64, 256, 256]               0\n",
      "           Conv2d-32         [-1, 64, 256, 256]          36,928\n",
      "             SiLU-33         [-1, 64, 256, 256]               0\n",
      "           Conv2d-34         [-1, 64, 256, 256]          36,928\n",
      "             SiLU-35         [-1, 64, 256, 256]               0\n",
      "           Conv2d-36         [-1, 64, 256, 256]          36,928\n",
      "             SiLU-37         [-1, 64, 256, 256]               0\n",
      "           Conv2d-38         [-1, 64, 256, 256]           4,160\n",
      "           Conv2d-39         [-1, 16, 256, 256]           1,040\n",
      "           Conv2d-40         [-1, 16, 127, 127]           2,320\n",
      "           Conv2d-41           [-1, 16, 41, 41]           2,320\n",
      "           Conv2d-42         [-1, 16, 256, 256]             272\n",
      "           Conv2d-43         [-1, 64, 256, 256]           1,088\n",
      "          Sigmoid-44         [-1, 64, 256, 256]               0\n",
      "              ESA-45         [-1, 64, 256, 256]               0\n",
      "             RLFB-46         [-1, 64, 256, 256]               0\n",
      "           Conv2d-47         [-1, 64, 256, 256]          36,928\n",
      "             SiLU-48         [-1, 64, 256, 256]               0\n",
      "           Conv2d-49         [-1, 64, 256, 256]          36,928\n",
      "             SiLU-50         [-1, 64, 256, 256]               0\n",
      "           Conv2d-51         [-1, 64, 256, 256]          36,928\n",
      "             SiLU-52         [-1, 64, 256, 256]               0\n",
      "           Conv2d-53         [-1, 64, 256, 256]           4,160\n",
      "           Conv2d-54         [-1, 16, 256, 256]           1,040\n",
      "           Conv2d-55         [-1, 16, 127, 127]           2,320\n",
      "           Conv2d-56           [-1, 16, 41, 41]           2,320\n",
      "           Conv2d-57         [-1, 16, 256, 256]             272\n",
      "           Conv2d-58         [-1, 64, 256, 256]           1,088\n",
      "          Sigmoid-59         [-1, 64, 256, 256]               0\n",
      "              ESA-60         [-1, 64, 256, 256]               0\n",
      "             RLFB-61         [-1, 64, 256, 256]               0\n",
      "           Conv2d-62         [-1, 64, 256, 256]          36,928\n",
      "             SiLU-63         [-1, 64, 256, 256]               0\n",
      "           Conv2d-64         [-1, 64, 256, 256]          36,928\n",
      "             SiLU-65         [-1, 64, 256, 256]               0\n",
      "           Conv2d-66         [-1, 64, 256, 256]          36,928\n",
      "             SiLU-67         [-1, 64, 256, 256]               0\n",
      "           Conv2d-68         [-1, 64, 256, 256]           4,160\n",
      "           Conv2d-69         [-1, 16, 256, 256]           1,040\n",
      "           Conv2d-70         [-1, 16, 127, 127]           2,320\n",
      "           Conv2d-71           [-1, 16, 41, 41]           2,320\n",
      "           Conv2d-72         [-1, 16, 256, 256]             272\n",
      "           Conv2d-73         [-1, 64, 256, 256]           1,088\n",
      "          Sigmoid-74         [-1, 64, 256, 256]               0\n",
      "              ESA-75         [-1, 64, 256, 256]               0\n",
      "             RLFB-76         [-1, 64, 256, 256]               0\n",
      "           Conv2d-77         [-1, 64, 256, 256]          36,928\n",
      "             SiLU-78         [-1, 64, 256, 256]               0\n",
      "           Conv2d-79         [-1, 64, 256, 256]          36,928\n",
      "             SiLU-80         [-1, 64, 256, 256]               0\n",
      "           Conv2d-81         [-1, 64, 256, 256]          36,928\n",
      "             SiLU-82         [-1, 64, 256, 256]               0\n",
      "           Conv2d-83         [-1, 64, 256, 256]           4,160\n",
      "           Conv2d-84         [-1, 16, 256, 256]           1,040\n",
      "           Conv2d-85         [-1, 16, 127, 127]           2,320\n",
      "           Conv2d-86           [-1, 16, 41, 41]           2,320\n",
      "           Conv2d-87         [-1, 16, 256, 256]             272\n",
      "           Conv2d-88         [-1, 64, 256, 256]           1,088\n",
      "          Sigmoid-89         [-1, 64, 256, 256]               0\n",
      "              ESA-90         [-1, 64, 256, 256]               0\n",
      "             RLFB-91         [-1, 64, 256, 256]               0\n",
      "           Conv2d-92         [-1, 64, 256, 256]          36,928\n",
      "             SiLU-93         [-1, 64, 256, 256]               0\n",
      "           Conv2d-94         [-1, 64, 256, 256]          36,928\n",
      "             SiLU-95         [-1, 64, 256, 256]               0\n",
      "           Conv2d-96         [-1, 64, 256, 256]          36,928\n",
      "             SiLU-97         [-1, 64, 256, 256]               0\n",
      "           Conv2d-98         [-1, 64, 256, 256]           4,160\n",
      "           Conv2d-99         [-1, 16, 256, 256]           1,040\n",
      "          Conv2d-100         [-1, 16, 127, 127]           2,320\n",
      "          Conv2d-101           [-1, 16, 41, 41]           2,320\n",
      "          Conv2d-102         [-1, 16, 256, 256]             272\n",
      "          Conv2d-103         [-1, 64, 256, 256]           1,088\n",
      "         Sigmoid-104         [-1, 64, 256, 256]               0\n",
      "             ESA-105         [-1, 64, 256, 256]               0\n",
      "            RLFB-106         [-1, 64, 256, 256]               0\n",
      "          Conv2d-107         [-1, 64, 256, 256]          36,928\n",
      "            SiLU-108         [-1, 64, 256, 256]               0\n",
      "          Conv2d-109         [-1, 64, 256, 256]          36,928\n",
      "            SiLU-110         [-1, 64, 256, 256]               0\n",
      "          Conv2d-111         [-1, 64, 256, 256]          36,928\n",
      "            SiLU-112         [-1, 64, 256, 256]               0\n",
      "          Conv2d-113         [-1, 64, 256, 256]           4,160\n",
      "          Conv2d-114         [-1, 16, 256, 256]           1,040\n",
      "          Conv2d-115         [-1, 16, 127, 127]           2,320\n",
      "          Conv2d-116           [-1, 16, 41, 41]           2,320\n",
      "          Conv2d-117         [-1, 16, 256, 256]             272\n",
      "          Conv2d-118         [-1, 64, 256, 256]           1,088\n",
      "         Sigmoid-119         [-1, 64, 256, 256]               0\n",
      "             ESA-120         [-1, 64, 256, 256]               0\n",
      "            RLFB-121         [-1, 64, 256, 256]               0\n",
      "          Conv2d-122         [-1, 64, 256, 256]          36,928\n",
      "            SiLU-123         [-1, 64, 256, 256]               0\n",
      "          Conv2d-124         [-1, 64, 256, 256]          36,928\n",
      "            SiLU-125         [-1, 64, 256, 256]               0\n",
      "          Conv2d-126         [-1, 64, 256, 256]          36,928\n",
      "            SiLU-127         [-1, 64, 256, 256]               0\n",
      "          Conv2d-128         [-1, 64, 256, 256]           4,160\n",
      "          Conv2d-129         [-1, 16, 256, 256]           1,040\n",
      "          Conv2d-130         [-1, 16, 127, 127]           2,320\n",
      "          Conv2d-131           [-1, 16, 41, 41]           2,320\n",
      "          Conv2d-132         [-1, 16, 256, 256]             272\n",
      "          Conv2d-133         [-1, 64, 256, 256]           1,088\n",
      "         Sigmoid-134         [-1, 64, 256, 256]               0\n",
      "             ESA-135         [-1, 64, 256, 256]               0\n",
      "            RLFB-136         [-1, 64, 256, 256]               0\n",
      "          Conv2d-137         [-1, 64, 256, 256]          36,928\n",
      "            SiLU-138         [-1, 64, 256, 256]               0\n",
      "          Conv2d-139         [-1, 64, 256, 256]          36,928\n",
      "            SiLU-140         [-1, 64, 256, 256]               0\n",
      "          Conv2d-141         [-1, 64, 256, 256]          36,928\n",
      "            SiLU-142         [-1, 64, 256, 256]               0\n",
      "          Conv2d-143         [-1, 64, 256, 256]           4,160\n",
      "          Conv2d-144         [-1, 16, 256, 256]           1,040\n",
      "          Conv2d-145         [-1, 16, 127, 127]           2,320\n",
      "          Conv2d-146           [-1, 16, 41, 41]           2,320\n",
      "          Conv2d-147         [-1, 16, 256, 256]             272\n",
      "          Conv2d-148         [-1, 64, 256, 256]           1,088\n",
      "         Sigmoid-149         [-1, 64, 256, 256]               0\n",
      "             ESA-150         [-1, 64, 256, 256]               0\n",
      "            RLFB-151         [-1, 64, 256, 256]               0\n",
      "          Conv2d-152         [-1, 64, 256, 256]          36,928\n",
      "            SiLU-153         [-1, 64, 256, 256]               0\n",
      "          Conv2d-154         [-1, 64, 256, 256]          36,928\n",
      "            SiLU-155         [-1, 64, 256, 256]               0\n",
      "          Conv2d-156         [-1, 64, 256, 256]          36,928\n",
      "            SiLU-157         [-1, 64, 256, 256]               0\n",
      "          Conv2d-158         [-1, 64, 256, 256]           4,160\n",
      "          Conv2d-159         [-1, 16, 256, 256]           1,040\n",
      "          Conv2d-160         [-1, 16, 127, 127]           2,320\n",
      "          Conv2d-161           [-1, 16, 41, 41]           2,320\n",
      "          Conv2d-162         [-1, 16, 256, 256]             272\n",
      "          Conv2d-163         [-1, 64, 256, 256]           1,088\n",
      "         Sigmoid-164         [-1, 64, 256, 256]               0\n",
      "             ESA-165         [-1, 64, 256, 256]               0\n",
      "            RLFB-166         [-1, 64, 256, 256]               0\n",
      "          Conv2d-167         [-1, 64, 256, 256]          36,928\n",
      "            SiLU-168         [-1, 64, 256, 256]               0\n",
      "          Conv2d-169         [-1, 64, 256, 256]          36,928\n",
      "            SiLU-170         [-1, 64, 256, 256]               0\n",
      "          Conv2d-171         [-1, 64, 256, 256]          36,928\n",
      "            SiLU-172         [-1, 64, 256, 256]               0\n",
      "          Conv2d-173         [-1, 64, 256, 256]           4,160\n",
      "          Conv2d-174         [-1, 16, 256, 256]           1,040\n",
      "          Conv2d-175         [-1, 16, 127, 127]           2,320\n",
      "          Conv2d-176           [-1, 16, 41, 41]           2,320\n",
      "          Conv2d-177         [-1, 16, 256, 256]             272\n",
      "          Conv2d-178         [-1, 64, 256, 256]           1,088\n",
      "         Sigmoid-179         [-1, 64, 256, 256]               0\n",
      "             ESA-180         [-1, 64, 256, 256]               0\n",
      "            RLFB-181         [-1, 64, 256, 256]               0\n",
      "          Conv2d-182         [-1, 64, 256, 256]          36,928\n",
      "            SiLU-183         [-1, 64, 256, 256]               0\n",
      "          Conv2d-184         [-1, 64, 256, 256]          36,928\n",
      "            SiLU-185         [-1, 64, 256, 256]               0\n",
      "          Conv2d-186         [-1, 64, 256, 256]          36,928\n",
      "            SiLU-187         [-1, 64, 256, 256]               0\n",
      "          Conv2d-188         [-1, 64, 256, 256]           4,160\n",
      "          Conv2d-189         [-1, 16, 256, 256]           1,040\n",
      "          Conv2d-190         [-1, 16, 127, 127]           2,320\n",
      "          Conv2d-191           [-1, 16, 41, 41]           2,320\n",
      "          Conv2d-192         [-1, 16, 256, 256]             272\n",
      "          Conv2d-193         [-1, 64, 256, 256]           1,088\n",
      "         Sigmoid-194         [-1, 64, 256, 256]               0\n",
      "             ESA-195         [-1, 64, 256, 256]               0\n",
      "            RLFB-196         [-1, 64, 256, 256]               0\n",
      "          Conv2d-197         [-1, 64, 256, 256]          36,928\n",
      "            SiLU-198         [-1, 64, 256, 256]               0\n",
      "          Conv2d-199         [-1, 64, 256, 256]          36,928\n",
      "            SiLU-200         [-1, 64, 256, 256]               0\n",
      "          Conv2d-201         [-1, 64, 256, 256]          36,928\n",
      "            SiLU-202         [-1, 64, 256, 256]               0\n",
      "          Conv2d-203         [-1, 64, 256, 256]           4,160\n",
      "          Conv2d-204         [-1, 16, 256, 256]           1,040\n",
      "          Conv2d-205         [-1, 16, 127, 127]           2,320\n",
      "          Conv2d-206           [-1, 16, 41, 41]           2,320\n",
      "          Conv2d-207         [-1, 16, 256, 256]             272\n",
      "          Conv2d-208         [-1, 64, 256, 256]           1,088\n",
      "         Sigmoid-209         [-1, 64, 256, 256]               0\n",
      "             ESA-210         [-1, 64, 256, 256]               0\n",
      "            RLFB-211         [-1, 64, 256, 256]               0\n",
      "          Conv2d-212         [-1, 64, 256, 256]          36,928\n",
      "            SiLU-213         [-1, 64, 256, 256]               0\n",
      "          Conv2d-214         [-1, 64, 256, 256]          36,928\n",
      "            SiLU-215         [-1, 64, 256, 256]               0\n",
      "          Conv2d-216         [-1, 64, 256, 256]          36,928\n",
      "            SiLU-217         [-1, 64, 256, 256]               0\n",
      "          Conv2d-218         [-1, 64, 256, 256]           4,160\n",
      "          Conv2d-219         [-1, 16, 256, 256]           1,040\n",
      "          Conv2d-220         [-1, 16, 127, 127]           2,320\n",
      "          Conv2d-221           [-1, 16, 41, 41]           2,320\n",
      "          Conv2d-222         [-1, 16, 256, 256]             272\n",
      "          Conv2d-223         [-1, 64, 256, 256]           1,088\n",
      "         Sigmoid-224         [-1, 64, 256, 256]               0\n",
      "             ESA-225         [-1, 64, 256, 256]               0\n",
      "            RLFB-226         [-1, 64, 256, 256]               0\n",
      "          Conv2d-227         [-1, 64, 256, 256]          36,928\n",
      "            SiLU-228         [-1, 64, 256, 256]               0\n",
      "          Conv2d-229         [-1, 64, 256, 256]          36,928\n",
      "            SiLU-230         [-1, 64, 256, 256]               0\n",
      "          Conv2d-231         [-1, 64, 256, 256]          36,928\n",
      "            SiLU-232         [-1, 64, 256, 256]               0\n",
      "          Conv2d-233         [-1, 64, 256, 256]           4,160\n",
      "          Conv2d-234         [-1, 16, 256, 256]           1,040\n",
      "          Conv2d-235         [-1, 16, 127, 127]           2,320\n",
      "          Conv2d-236           [-1, 16, 41, 41]           2,320\n",
      "          Conv2d-237         [-1, 16, 256, 256]             272\n",
      "          Conv2d-238         [-1, 64, 256, 256]           1,088\n",
      "         Sigmoid-239         [-1, 64, 256, 256]               0\n",
      "             ESA-240         [-1, 64, 256, 256]               0\n",
      "            RLFB-241         [-1, 64, 256, 256]               0\n",
      "          Conv2d-242          [-1, 3, 256, 256]           1,731\n",
      "          Conv2d-243         [-1, 12, 256, 256]             336\n",
      "    PixelShuffle-244          [-1, 3, 512, 512]               0\n",
      "            ReLU-245          [-1, 3, 512, 512]               0\n",
      "SubPixelConvBlock-246          [-1, 3, 512, 512]               0\n",
      "================================================================\n",
      "Total params: 1,955,603\n",
      "Trainable params: 1,955,603\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.75\n",
      "Forward/backward pass size (MB): 5980.29\n",
      "Params size (MB): 7.46\n",
      "Estimated Total Size (MB): 5988.50\n",
      "----------------------------------------------------------------\n",
      "----------\n",
      "epoch 1/2\n",
      "Step 1/46, train_loss: 0.4411, step time: 0.8028 sec\n",
      "Step 2/46, train_loss: 0.4342, step time: 0.4367 sec\n",
      "Step 3/46, train_loss: 0.4401, step time: 0.4389 sec\n",
      "Step 4/46, train_loss: 0.4677, step time: 0.4365 sec\n",
      "Step 5/46, train_loss: 0.4349, step time: 0.4353 sec\n",
      "Step 6/46, train_loss: 0.4411, step time: 0.4365 sec\n",
      "Step 7/46, train_loss: 0.4335, step time: 0.4381 sec\n",
      "Step 8/46, train_loss: 0.4289, step time: 0.4380 sec\n",
      "Step 9/46, train_loss: 0.4627, step time: 0.4354 sec\n",
      "Step 10/46, train_loss: 0.4427, step time: 0.4334 sec\n",
      "Step 11/46, train_loss: 0.4359, step time: 0.4475 sec\n",
      "Step 12/46, train_loss: 0.4294, step time: 0.4470 sec\n",
      "Step 13/46, train_loss: 0.4345, step time: 0.4478 sec\n",
      "Step 14/46, train_loss: 0.4366, step time: 0.4465 sec\n",
      "Step 15/46, train_loss: 0.4374, step time: 0.4437 sec\n",
      "Step 16/46, train_loss: 0.4334, step time: 0.4292 sec\n",
      "Step 17/46, train_loss: 0.4376, step time: 0.4313 sec\n",
      "Step 18/46, train_loss: 0.4337, step time: 0.4322 sec\n",
      "Step 19/46, train_loss: 0.4249, step time: 0.4357 sec\n",
      "Step 20/46, train_loss: 0.4314, step time: 0.4348 sec\n",
      "Step 21/46, train_loss: 0.4309, step time: 0.4333 sec\n",
      "Step 22/46, train_loss: 0.4588, step time: 0.4375 sec\n",
      "Step 23/46, train_loss: 0.4280, step time: 0.4375 sec\n",
      "Step 24/46, train_loss: 0.4255, step time: 0.4371 sec\n",
      "Step 25/46, train_loss: 0.4336, step time: 0.4374 sec\n",
      "Step 26/46, train_loss: 0.4815, step time: 0.4364 sec\n",
      "Step 27/46, train_loss: 0.4325, step time: 0.4367 sec\n",
      "Step 28/46, train_loss: 0.4290, step time: 0.4369 sec\n",
      "Step 29/46, train_loss: 0.4278, step time: 0.4363 sec\n",
      "Step 30/46, train_loss: 0.4299, step time: 0.4352 sec\n",
      "Step 31/46, train_loss: 0.4284, step time: 0.4351 sec\n",
      "Step 32/46, train_loss: 0.4579, step time: 0.4335 sec\n",
      "Step 33/46, train_loss: 0.4570, step time: 0.4362 sec\n",
      "Step 34/46, train_loss: 0.4283, step time: 0.4349 sec\n",
      "Step 35/46, train_loss: 0.4262, step time: 0.4332 sec\n",
      "Step 36/46, train_loss: 0.4291, step time: 0.4363 sec\n",
      "Step 37/46, train_loss: 0.4250, step time: 0.4344 sec\n",
      "Step 38/46, train_loss: 0.4237, step time: 0.4367 sec\n",
      "Step 39/46, train_loss: 0.4250, step time: 0.4330 sec\n",
      "Step 40/46, train_loss: 0.4255, step time: 0.4348 sec\n",
      "Step 41/46, train_loss: 0.4245, step time: 0.4338 sec\n",
      "Step 42/46, train_loss: 0.4231, step time: 0.4358 sec\n",
      "Step 43/46, train_loss: 0.4267, step time: 0.4357 sec\n",
      "Step 44/46, train_loss: 0.4251, step time: 0.4319 sec\n",
      "Step 45/46, train_loss: 0.4253, step time: 0.4370 sec\n",
      "Step 46/46, train_loss: 0.4223, step time: 0.1738 sec\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "step() missing 1 required positional argument: 'metrics'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 48\u001b[0m\n\u001b[1;32m     45\u001b[0m     model_summary(model, device)\n\u001b[1;32m     46\u001b[0m     setup_training(model, device, train_loader, val_loader)\n\u001b[0;32m---> 48\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 46\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m train_loader, val_loader \u001b[38;5;241m=\u001b[39m dataloaders(train_dataset, val_dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m24\u001b[39m)\n\u001b[1;32m     45\u001b[0m model_summary(model, device)\n\u001b[0;32m---> 46\u001b[0m \u001b[43msetup_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 12\u001b[0m, in \u001b[0;36msetup_training\u001b[0;34m(model, device, train_loader, val_loader, epochs, patience)\u001b[0m\n\u001b[1;32m      9\u001b[0m loss_function \u001b[38;5;241m=\u001b[39m CharbonnierLoss(epsilon\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-6\u001b[39m)\n\u001b[1;32m     10\u001b[0m lr_scheduler \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mlr_scheduler\u001b[38;5;241m.\u001b[39mReduceLROnPlateau(optimizer, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpatience\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./model_output\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Specify the output directory\u001b[39;49;00m\n\u001b[1;32m     24\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Abul Hasan/Resolution-Enhancement-of-Solar-Magnetograms-main/Trainning_Loop.py:87\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, optimizer, loss_function, device, epochs, patience, val_interval, lr_scheduler, output_dir)\u001b[0m\n\u001b[1;32m     80\u001b[0m     epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m     82\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStep \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstep\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(train_loader)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     83\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, train_loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     84\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, step time: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(time\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mstep_start)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m sec\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     85\u001b[0m     )\n\u001b[0;32m---> 87\u001b[0m \u001b[43mlr_scheduler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m epoch_loss \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader)\n\u001b[1;32m     89\u001b[0m epoch_loss_values\u001b[38;5;241m.\u001b[39mappend(epoch_loss)\n",
      "\u001b[0;31mTypeError\u001b[0m: step() missing 1 required positional argument: 'metrics'"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"CUDA is available!\")\n",
    "        print(f\"Number of available GPUs: {torch.cuda.device_count()}\")\n",
    "        print(f\"Current device: {torch.cuda.current_device()}\")\n",
    "        print(f\"Device name: {torch.cuda.get_device_name(torch.cuda.current_device())}\")\n",
    "    else:\n",
    "        print(\"CUDA is not available.\")\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model = MESR(in_channels=3, mid_channels=64, out_channels=3, num_blocks=16)\n",
    "\n",
    "    transform_lr = transforms.Compose([\n",
    "        transforms.Resize((128, 128)),  \n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "    ])\n",
    "\n",
    "    transform_hr = transforms.Compose([\n",
    "        transforms.Resize((256, 256)), \n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "    ])\n",
    "\n",
    "    # load the dataset\n",
    "    lr_dir = \"/home/user/Desktop/Abul Hasan/Dataset/LRHR dataset/renamedsoho\"\n",
    "    hr_dir = \"/home/user/Desktop/Abul Hasan/Dataset/LRHR dataset/renamedsdo\"\n",
    "\n",
    "    # dataset instance with separate transformations for LR and HR images\n",
    "    full_dataset = SuperResolutionDataset(\n",
    "        lr_dir=lr_dir,\n",
    "        hr_dir=hr_dir,\n",
    "        lr_transform=transform_lr,\n",
    "        hr_transform=transform_hr\n",
    "    )\n",
    "\n",
    "    #splitting the dataset\n",
    "    train_size = int(0.8 * len(full_dataset))\n",
    "    val_size = len(full_dataset) - train_size\n",
    "    \n",
    "    train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
    "    train_loader, val_loader = dataloaders(train_dataset, val_dataset, batch_size=24)\n",
    "\n",
    "    model_summary(model, device)\n",
    "    setup_training(model, device, train_loader, val_loader)\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "abul",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
